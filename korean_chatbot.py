# kor_chatbot.py â€“ KSSB ë° IFRS êµ­ë¬¸ ì „ìš© ESG ì±—ë´‡

import os
import re
import streamlit as st
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.messages import SystemMessage, HumanMessage
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMListwiseRerank

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… ëª¨ë¸ ì •ì˜
llm = ChatOpenAI(model="gpt-4o", temperature=0)
embedding_model = OpenAIEmbeddings()

# âœ… í´ë¦° í…ìŠ¤íŠ¸ í•¨ìˆ˜
def clean_text(text: str) -> str:
    lines = text.splitlines()
    cleaned = []
    for line in lines:
        stripped = line.strip()
        if not stripped:
            continue
        if re.match(r"^\d{1,2}$", stripped):
            continue
        cleaned.append(stripped)
    return ' '.join(cleaned)

# âœ… ë²¡í„°DB ë¡œë”©
kor_vector_paths = {
    "IFRS_S1": r"D:\bit_esg\python\esg_chatbot_project\src\vector_finish\KOKRvectorstores\KOKRvectorstores\KOR_IFRS_S1_2nd",
    "IFRS_S2": r"D:\bit_esg\python\esg_chatbot_project\src\vector_finish\KOKRvectorstores\KOKRvectorstores\KOR_IFRS_S2_2nd",
    "KSSB1": r"D:\bit_esg\python\esg_chatbot_project\src\vector_finish\KOKRvectorstores\KOKRvectorstores\KSSB_01_2nd",
    "KSSB2": r"D:\bit_esg\python\esg_chatbot_project\src\vector_finish\KOKRvectorstores\KOKRvectorstores\KSSB_02_2nd",
    "KSSB101": r"D:\bit_esg\python\esg_chatbot_project\src\vector_finish\KOKRvectorstores\KOKRvectorstores\KSSB_101_2nd",
}

kor_dbs = {
    name: FAISS.load_local(path, embedding_model, allow_dangerous_deserialization=True)
    for name, path in kor_vector_paths.items()
}

# âœ… ê¸°ì¤€ ìë™ ë¶„ë¥˜
def classify_kor_standards(query: str):
    prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë³´ê³  ê´€ë ¨ ìˆëŠ” ê¸°ì¤€ì„œë“¤ì„ ê³¨ë¼ì¤˜. ì¤‘ë³µ ì„ íƒ ê°€ëŠ¥í•´.
ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
ì„ íƒ ê°€ëŠ¥í•œ ê¸°ì¤€: IFRS_S1, IFRS_S2, KSSB1, KSSB2, KSSB101
ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë°˜í™˜í•´ì¤˜. ì˜ˆì‹œ: ["IFRS_S1", "KSSB2"]
"""
    response = llm([
        SystemMessage(content="ë„ˆëŠ” ESG ê¸°ì¤€ì„œ ë¶„ë¥˜ ì „ë¬¸ê°€ì•¼."),
        HumanMessage(content=prompt)
    ])
    try:
        return eval(response.content)
    except:
        return list(kor_dbs.keys())

# âœ… ê¸°ì¤€ë³„ ë¬¸ì„œ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„±
def process_kor_standard(standard, db, query_ko):
    try:
        multi_retriever = MultiQueryRetriever.from_llm(
            retriever=db.as_retriever(search_kwargs={"k": 4}),
            llm=llm
        )
        reranker = LLMListwiseRerank.from_llm(llm=llm, top_n=2)
        compressor = ContextualCompressionRetriever(
            base_retriever=multi_retriever,
            base_compressor=reranker
        )
        docs = compressor.invoke(query_ko)
        if not docs:
            return (standard, None, [])

        context_blocks = []
        references = []
        for doc in docs:
            meta = doc.metadata
            source = meta.get("source", "")
            citation = f"[ì¶œì²˜: {standard} - {source or 'í•´ë‹¹ ë¬¸ë‹¨'}]"
            context_blocks.append(f"{citation}\n{doc.page_content}")
            references.append({
                "standard": standard,
                "source": source or "ì•Œ ìˆ˜ ì—†ìŒ",
                "content": doc.page_content
            })

        context = "\n\n".join(context_blocks)
        system_msg = SystemMessage(
            content=f"{standard} ê¸°ì¤€ì„œ ì „ë¬¸ê°€ë¡œì„œ, ì•„ë˜ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\n\n[ë¬¸ì„œ]\n{context}\n\n[ì§ˆë¬¸]\n{query_ko}"
        )
        user_msg = HumanMessage(content=query_ko)
        response = llm([system_msg, user_msg])
        return (standard, response.content, references)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ - {standard}: {e}")
        return (standard, None, [])

# âœ… ê¸°ì¤€ë³„ ì‘ë‹µ í†µí•©
def generate_kor_responses(query_ko: str, selected_standards: list):
    responses = {}
    references = {}

    with ThreadPoolExecutor() as executor:
        futures = [
            executor.submit(process_kor_standard, std, kor_dbs[std], query_ko)
            for std in selected_standards if std in kor_dbs
        ]
        for future in futures:
            std, resp, refs = future.result()
            if resp:
                responses[std] = resp
                references[std] = refs
            else:
                print(f"â›” ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ: {std}, ì‘ë‹µ ì œì™¸ë¨")

    return responses, references

# âœ… Streamlit ì‹¤í–‰ í•¨ìˆ˜
def run_kor_chatbot_app():
    import os
    import re
    import streamlit as st
    from io import BytesIO
    import pythoncom
    from docx import Document
    import tempfile
    from docx2pdf import convert

    def remove_control_characters(text: str) -> str:
        return re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f]', '', text)

    # st.set_page_config(page_title="ESG ê³µì‹œ ë¹„êµ ì±—ë´‡", layout="wide")
    st.title("ğŸŒºK-Mate")

    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œì„ ì–´ë–»ê²Œ ê³µì‹œí•´ì•¼ í•˜ë‚˜ìš”?)")

    if st.button("ì…ë ¥") and user_input:
        with st.spinner("ì§ˆë¬¸ ë¶„ì„ ì¤‘: ê´€ë ¨ ê¸°ì¤€ì„œë¥¼ ì‹ë³„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            selected = classify_kor_standards(user_input)
            st.markdown(f"âœ… ì„ íƒëœ ê¸°ì¤€ì„œ: {', '.join(selected) if selected else 'ì—†ìŒ'}")

        with st.spinner("ê¸°ì¤€ë³„ ë¬¸ì„œ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„± ì¤‘..."):
            responses, references = generate_kor_responses(user_input, selected)
        
        st.session_state.responses = responses
        st.session_state.references = references
        st.session_state.user_input = user_input
         
    if "user_input" in st.session_state:
        responses = st.session_state.responses
        references = st.session_state.references
        user_input = st.session_state.user_input

        # st.header(f"ğŸ“„ ê¸°ì¤€ë³„ ìƒì„¸ ì‘ë‹µ ë³´ê¸°")
        # for std, resp in responses.items():
        #     st.markdown(f"### {std} ì‘ë‹µ")
        #     st.write(resp)

        if responses:
            st.header("ğŸ“„ ê¸°ì¤€ë³„ ìƒì„¸ ì‘ë‹µ ë³´ê¸°")
            for std, resp in responses.items():
                st.markdown(f"### {std} ì‘ë‹µ")
                st.write(resp)
        else:
            st.header("ğŸ“„ ê¸°ì¤€ë³„ ìƒì„¸ ì‘ë‹µ ì—†ìŒ")

        with st.expander("ğŸ“š ì¸ìš©ëœ ë¬¸ì„œ ì¶œì²˜ ë³´ê¸°"):
            for std, refs in references.items():
                st.markdown(f"## {std} ë¬¸ì„œ ì¸ìš©")
                for ref in refs:
                    cleaned_text = clean_text(ref['content'])
                    content_html = f"""
                    <div style='margin-bottom:1.5em; padding:1em; border:1px solid #ccc; border-radius:10px; background-color:#f9f9f9'>
                        <p><b>ğŸ“Œ ì†ŒìŠ¤:</b> {ref.get("source", "ì—†ìŒ")}</p>
                        <pre style='white-space: pre-wrap; font-size: 14px; color: auto; line-height: 1.5;'>{cleaned_text}</pre>
                    </div>
                    """
                    st.markdown(content_html, unsafe_allow_html=True)

        # Word ë¬¸ì„œ ìƒì„±
        doc = Document()
        doc.add_heading('ESG ê³µì‹œ ë¹„êµ ì±—ë´‡ ê²°ê³¼', 0)
        doc.add_heading('ì§ˆë¬¸', level=1)
        doc.add_paragraph(user_input)
        doc.add_heading('ğŸ“„ ê¸°ì¤€ë³„ ì‘ë‹µ', level=1)
        for std, resp in responses.items():
            doc.add_heading(std, level=2)
            doc.add_paragraph(resp)
        doc.add_heading('ğŸ“š ì¸ìš© ë¬¸ì„œ', level=1)
        for std, refs in references.items():
            doc.add_heading(std, level=2)
            for ref in refs:
                doc.add_paragraph(f"ì¶œì²˜: {ref['source']}")
                safe_text = remove_control_characters(clean_text(ref['content']))
                doc.add_paragraph(safe_text)

        # Word â†’ BytesIO
        doc_io = BytesIO()
        doc.save(doc_io)
        doc_io.seek(0)

        st.download_button(
            label="â¬‡ï¸ Word íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=doc_io,
            file_name="esg_ë‹µë³€ê¸°ë¡.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )

        # PDF ë‹¤ìš´ë¡œë“œ
        def convert_docx_to_pdf(doc: Document) -> BytesIO:
            pythoncom.CoInitialize()
            with tempfile.TemporaryDirectory() as tmpdir:
                docx_path = os.path.join(tmpdir, "temp.docx")
                pdf_path = os.path.join(tmpdir, "temp.pdf")
                doc.save(docx_path)
                convert(docx_path, pdf_path)
                with open(pdf_path, "rb") as f:
                    return BytesIO(f.read())

        # âœ… PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì²˜ë¦¬
        try:
            pdf_bytes = convert_docx_to_pdf(doc)
            st.download_button(
                label="â¬‡ï¸ PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=pdf_bytes,
                file_name="esg_ë‹µë³€ê¸°ë¡.pdf",
                mime="application/pdf"
            )
        except Exception as e:
            st.warning("âš ï¸ PDF ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. Word íŒŒì¼ì€ ì •ìƒ ì €ì¥ë©ë‹ˆë‹¤.")
            st.text(str(e))
